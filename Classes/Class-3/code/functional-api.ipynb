{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Lets see how else we can build models.\n",
    "\n",
    "Some of the examples are from [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras - easy to start with but also possible to provide deep dives for those who need it.  \n",
    "NLP and Image Processing are such needs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thing to remember - Keras is API based.  \n",
    "Sequential is a list of stacked layers - there lies its first limitation.\n",
    "So:\n",
    "1. Only feedforward models.\n",
    "2. Only one input (not for example a text/picture and its metadata)\n",
    "3. Only one output (not for example multiple regression/classification predictions for one data point)\n",
    "4. Linear topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in Python list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error - model is not built yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can name every layer, model and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that you can see the summary without actually building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we did - add another layer on top of the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets image a usecase of dealing with support tickets.  \n",
    "We need to move tickets to appropriate departaments. What we know:  \n",
    "1. Title of ticket (text)\n",
    "2. Text of the ticket (text)\n",
    "3. Tags added by the user (one-hot encoding)\n",
    "\n",
    "We expect to know:\n",
    "1. Priority of the ticket (regression)\n",
    "2. Departament where to move the ticket (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000 #this is what we did on bert - how many words do we use from the dictionary\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 21ms/step - loss: 21.9741 - priority_loss: 0.3349 - department_loss: 21.6392 - priority_mean_absolute_error: 0.5032 - department_accuracy: 0.2242\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 23.2868 - priority_loss: 0.3454 - department_loss: 22.9414 - priority_mean_absolute_error: 0.5125 - department_accuracy: 0.2578\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using names - for complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 22ms/step - loss: 31.4611 - priority_loss: 0.3169 - department_loss: 31.1442 - priority_mean_absolute_error: 0.4839 - department_accuracy: 0.2727\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 46.4265 - priority_loss: 0.3205 - department_loss: 46.1060 - priority_mean_absolute_error: 0.4875 - department_accuracy: 0.1102\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot Model](../img/plot-ticketmodel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.manning.com/books/deep-learning-with-python  \n",
    "\n",
    "This can mean retrieving fetures from another models and reusing components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1c9f91339a0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1c9f9133a00>,\n",
       " <keras.engine.input_layer.InputLayer at 0x1c9f9122c70>,\n",
       " <keras.layers.merge.Concatenate at 0x1c9f9122340>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9d38da070>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9d38daf40>,\n",
       " <keras.layers.core.dense.Dense at 0x1c9fa12db80>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new prediction to the existing model. Easy! \n",
    "Now: 3 categories of difficulty resolving the ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're in charge, you can write a call and init hovewer you like without the graph-like constraints of Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 19ms/step - loss: 36.7537 - output_1_loss: 0.3170 - output_2_loss: 36.4367 - output_1_mean_absolute_error: 0.4840 - output_2_accuracy: 0.1750\n",
      "40/40 [==============================] - 1s 7ms/step - loss: 33.4412 - output_1_loss: 0.3205 - output_2_loss: 33.1208 - output_1_mean_absolute_error: 0.4875 - output_2_accuracy: 0.5758\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your Python code.  \n",
    "You cannot:\n",
    "1. Use summary()\n",
    "2. Use plot_model()\n",
    "3. Just snap pieces together - this is your model with potencially more room for mistakes and debugging issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Subclass in Functional Model, A Funtional Model inside a Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras, there is a spectrum of ways to build models — from the simplest approach (Sequential models) to the most flexible one (model subclassing).\n",
    "\n",
    "There is no single “correct” choice.  \n",
    "Each approach has advantages and limitations, and the right one depends on the problem you are solving.\n",
    "\n",
    "In most practical situations, the **Functional API** offers the best balance between clarity and flexibility. It allows you to explicitly define how layers are connected, which makes your model structure transparent and easy to analyze. This becomes particularly useful when you want to visualize the architecture, inspect intermediate outputs, or extract features.\n",
    "\n",
    "If your model can be represented as a directed acyclic graph of layers — which is true for most standard deep learning architectures — the Functional API is usually the recommended choice over full model subclassing.\n",
    "\n",
    "Throughout our work, we will primarily use the Functional API, because the models we study can be naturally expressed as graphs of layers. At the same time, we will often create custom (subclassed) layers when needed.\n",
    "\n",
    "In practice, combining Functional models with subclassed layers gives you both structure and flexibility — a clear architecture with the ability to customize internal behavior when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2944 - accuracy: 0.9129 - val_loss: 0.1508 - val_accuracy: 0.9555\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1661 - accuracy: 0.9527 - val_loss: 0.1247 - val_accuracy: 0.9656\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1387 - accuracy: 0.9630 - val_loss: 0.1155 - val_accuracy: 0.9700\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1157 - accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.2970 - accuracy: 0.9119 - rmse: 7.1787 - val_loss: 0.1565 - val_accuracy: 0.9537 - val_rmse: 7.3448\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1679 - accuracy: 0.9537 - rmse: 7.3537 - val_loss: 0.1228 - val_accuracy: 0.9677 - val_rmse: 7.4049\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1399 - accuracy: 0.9631 - rmse: 7.3904 - val_loss: 0.1161 - val_accuracy: 0.9705 - val_rmse: 7.4240\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9716 - rmse: 7.4361\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks are mechanisms that allow us to intervene in the training process.\n",
    "They are executed at specific moments during training (for example, at the end of each epoch).\n",
    "\n",
    "Instead of letting training run blindly, callbacks allow us to monitor, adjust, and control it.\n",
    "\n",
    "Below are common use cases.\n",
    "\n",
    "**Model Checkpointing**\n",
    "\n",
    "Saves the state of the model during training.\n",
    "\n",
    "This allows you to:\n",
    "- Keep the best-performing model\n",
    "- Resume training later\n",
    "- Avoid losing progress if training is interrupted\n",
    "\n",
    "Keras implementation:\n",
    "keras.callbacks.ModelCheckpoint\n",
    "\n",
    "**Early Stopping**\n",
    "\n",
    "Stops training when the validation metric (usually validation loss) stops improving.\n",
    "\n",
    "This helps prevent overfitting.\n",
    "It also ensures that the model parameters correspond to the best validation performance.\n",
    "\n",
    "Keras implementation:\n",
    "keras.callbacks.EarlyStopping\n",
    "\n",
    "**Learning Rate Scheduling**\n",
    "\n",
    "Adjusts the learning rate during training.\n",
    "\n",
    "This can:\n",
    "- Speed up convergence\n",
    "- Stabilize training\n",
    "- Help escape plateaus\n",
    "\n",
    "Two common options:\n",
    "\n",
    "keras.callbacks.LearningRateScheduler  \n",
    "→ manually defines how the learning rate changes\n",
    "\n",
    "keras.callbacks.ReduceLROnPlateau  \n",
    "→ automatically reduces learning rate when validation performance stops improving\n",
    "\n",
    "**Logging and Monitoring**\n",
    "\n",
    "Records training and validation metrics during training.\n",
    "\n",
    "This allows:\n",
    "- Tracking performance over time\n",
    "- Plotting learning curves\n",
    "- Diagnosing instability\n",
    "\n",
    "keras.callbacks.CSVLogger  \n",
    "→ saves metrics to a file\n",
    "\n",
    "Even the training progress bar in model.fit() is implemented as a callback.\n",
    "\n",
    "In practice, combining EarlyStopping and ModelCheckpoint is common and recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.2976 - accuracy: 0.9123 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.1663 - accuracy: 0.9537 - val_loss: 0.1211 - val_accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1388 - accuracy: 0.9627 - val_loss: 0.1166 - val_accuracy: 0.9716\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.1260 - accuracy: 0.9676 - val_loss: 0.1115 - val_accuracy: 0.9723\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1213 - accuracy: 0.9705 - val_loss: 0.1099 - val_accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1105 - accuracy: 0.9730 - val_loss: 0.1068 - val_accuracy: 0.9752\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1037 - accuracy: 0.9749 - val_loss: 0.1153 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1028 - accuracy: 0.9762 - val_loss: 0.1212 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1002 - accuracy: 0.9769 - val_loss: 0.1147 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0940 - accuracy: 0.9788 - val_loss: 0.1283 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983b65dc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 17s 10ms/step - loss: 0.2993 - accuracy: 0.9108 - val_loss: 0.1558 - val_accuracy: 0.9555\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1686 - accuracy: 0.9527 - val_loss: 0.1269 - val_accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1385 - accuracy: 0.9626 - val_loss: 0.1124 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1279 - accuracy: 0.9671 - val_loss: 0.1142 - val_accuracy: 0.9716\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.1187 - accuracy: 0.9707 - val_loss: 0.1178 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.1115 - accuracy: 0.9729 - val_loss: 0.1203 - val_accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 23s 14ms/step - loss: 0.1071 - accuracy: 0.9743 - val_loss: 0.1151 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 0.1037 - accuracy: 0.9761 - val_loss: 0.1284 - val_accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.0993 - accuracy: 0.9776 - val_loss: 0.1270 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.1322 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9e67eef10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is a browser-based application that you can run locally. It’s the best way to monitor everything that goes on inside your model during training. With TensorBoard, you can\n",
    "\n",
    "1. Visually monitor metrics during training\n",
    "2. Visualize your model architecture\n",
    "3. Visualize histograms of activations and gradients\n",
    "4. Explore embeddings in 3D\n",
    "5. If you’re monitoring more information than just the model’s final loss, you can develop a clearer vision of what the model does and doesn’t do, and you can make progress more quickly.\n",
    "\n",
    "The easiest way to use TensorBoard with a Keras model and the fit() method is the keras.callbacks.TensorBoard callback. In the simplest case, just specify where you want the callback to write logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2922 - accuracy: 0.9134 - val_loss: 0.1489 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1668 - accuracy: 0.9531 - val_loss: 0.1215 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1399 - accuracy: 0.9635 - val_loss: 0.1197 - val_accuracy: 0.9702\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1295 - accuracy: 0.9673 - val_loss: 0.1207 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1176 - accuracy: 0.9703 - val_loss: 0.1116 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1146 - accuracy: 0.9727 - val_loss: 0.1106 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1090 - accuracy: 0.9739 - val_loss: 0.1025 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1027 - accuracy: 0.9760 - val_loss: 0.1097 - val_accuracy: 0.9776\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.0981 - accuracy: 0.9777 - val_loss: 0.1128 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 0.1211 - val_accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c983e36850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10584), started 0:04:22 ago. (Use '!kill 10584' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87eb5a0e2b3b06b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87eb5a0e2b3b06b2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
