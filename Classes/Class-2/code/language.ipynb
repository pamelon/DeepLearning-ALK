{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6ef5f7",
   "metadata": {},
   "source": [
    "Lets now look into language.\n",
    "\n",
    "Some of the examples are from [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a33e18",
   "metadata": {},
   "source": [
    "## How do we deal with language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9b8b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in C:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages (2026.2.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0fa72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def split_chars(text):\n",
    "    return re.findall(r\".\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b522a631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', ' ', 'l', 'o', 'v', 'e', ' ', 'c', 'o', 'm', 'p', 'u']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = split_chars(\"I love computer science it is so much fun\")\n",
    "chars[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec55628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'computer', 'science', 'it', 'is', 'so', 'much', 'fun']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_words(text):\n",
    "    return re.findall(r\"[\\w]+|[.,!?;]\", text)\n",
    "\n",
    "split_words(\"I love computer science it is so much fun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f90e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = { \n",
    "    \"UNK\": 0,\n",
    "    \"I\": 1,\n",
    "    \"love\": 2,\n",
    "    \"computer\": 3,\n",
    "    \"science\": 4,\n",
    "    \"it\": 5,\n",
    "    \"is\": 6,\n",
    "    \"so\": 7,\n",
    "    \"much\": 8,\n",
    "    \"fun\": 9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b01b101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = split_words(\"I love computer science it is so much fun and games and more fun\")\n",
    "indices = [vocabulary.get(word, 0) for word in words]\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc15d18",
   "metadata": {},
   "source": [
    "This is what is called Tokenizer. We can create tokens from words making them numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9a63a",
   "metadata": {},
   "source": [
    "**Problems with Tokenization**\n",
    "\n",
    "Character-level tokenization\n",
    "\n",
    "- Very small vocabulary (e.g., ~64 symbols)  \n",
    "- Produces very long input sequences  \n",
    "- Long sequences increase computational cost  \n",
    "- Harder for models to capture long-range dependencies  \n",
    "\n",
    "Word-level tokenization\n",
    "\n",
    "- Produces much shorter sequences (efficient “compression”)  \n",
    "- Vocabulary grows extremely large for real-world datasets  \n",
    "- Large-scale corpora may require millions of unique tokens  \n",
    "- Restricting vocabulary size leads to many \"[UNK]\" tokens  \n",
    "- \"[UNK]\" tokens discard useful semantic information  \n",
    "\n",
    "General scaling problem\n",
    "\n",
    "- Modern datasets contain billions or trillions of words  \n",
    "- Pure word-level vocabularies become impractical  \n",
    "- Pure character-level models become inefficient  \n",
    "\n",
    "Motivation for subword tokenization\n",
    "\n",
    "Subword tokenization attempts to:\n",
    "\n",
    "- Reduce vocabulary size  \n",
    "- Avoid excessive \"[UNK]\" tokens  \n",
    "- Maintain manageable sequence length  \n",
    "- Balance efficiency and expressiveness  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c858c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def standardize(self, inputs):\n",
    "        return inputs.lower()\n",
    "\n",
    "    def split(self, inputs):\n",
    "        return re.findall(r\".\", inputs)\n",
    "\n",
    "    def index(self, tokens):\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.standardize(inputs)\n",
    "        tokens = self.split(inputs)\n",
    "        indices = self.index(tokens)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b80f5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def compute_char_vocabulary(inputs, max_size):\n",
    "    char_counts = collections.Counter()\n",
    "    for x in inputs:\n",
    "        x = x.lower()\n",
    "        tokens = re.findall(r\".\", x)\n",
    "        char_counts.update(tokens)\n",
    "    vocabulary = [\"[UNK]\"]\n",
    "    most_common = char_counts.most_common(max_size - len(vocabulary))\n",
    "    for token, count in most_common:\n",
    "        vocabulary.append(token)\n",
    "    return dict((token, i) for i, token in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e750d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.unk_id = vocabulary[\"[UNK]\"]\n",
    "\n",
    "    def standardize(self, inputs):\n",
    "        return inputs.lower()\n",
    "\n",
    "    def split(self, inputs):\n",
    "        return re.findall(r\"[\\w]+|[.,!?;]\", inputs)\n",
    "\n",
    "    def index(self, tokens):\n",
    "        return [self.vocabulary.get(t, self.unk_id) for t in tokens]\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        inputs = self.standardize(inputs)\n",
    "        tokens = self.split(inputs)\n",
    "        indices = self.index(tokens)\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c176fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_vocabulary(inputs, max_size):\n",
    "    word_counts = collections.Counter()\n",
    "    for x in inputs:\n",
    "        x = x.lower()\n",
    "        tokens = re.findall(r\"[\\w]+|[.,!?;]\", x)\n",
    "        word_counts.update(tokens)\n",
    "    vocabulary = [\"[UNK]\"]\n",
    "    most_common = word_counts.most_common(max_size - len(vocabulary))\n",
    "    for token, count in most_common:\n",
    "        vocabulary.append(token)\n",
    "    return dict((token, i) for i, token in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1026539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "filename = keras.utils.get_file(\n",
    "    origin=\"https://www.gutenberg.org/cache/epub/9109/pg9109.txt\",\n",
    ")\n",
    "moby_dick = list(open(filename, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "vocabulary_char = compute_char_vocabulary(moby_dick, max_size=100)\n",
    "char_tokenizer = CharTokenizer(vocabulary_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40fe356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11332d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary end: ['ß', '©', '£', '\\x8d', 'ú', '°', '±', '`', 'ä', '‘']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary end:\", list(vocabulary_char.keys())[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1c49454",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_word = compute_word_vocabulary(moby_dick, max_size=2000)\n",
    "word_tokenizer = WordTokenizer(vocabulary_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b275b218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea0e8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary end: ['relevant', 'signal', 'mary', 'aware', 'phrase', 'increased', 'june', 'ellipsis', 'opinions', 'vs']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary end:\", list(vocabulary_word.keys())[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c3a5f",
   "metadata": {},
   "source": [
    "Subword tokenization is a compromise between word-level and character-level tokenization. Instead of splitting text strictly into full words or single characters, it breaks words into frequently occurring subunits. \n",
    "\n",
    "Subword tokenization is a compromise between word-level and character-level tokenization.  \n",
    "Instead of splitting text strictly into full words or single characters, it breaks words into frequently occurring subunits.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Character-level tokenization of **\"playing\"**:\n",
    "  p, l, a, y, i, n, g  \n",
    "  (long sequence, but very small vocabulary)\n",
    "\n",
    "- Word-level tokenization of **\"playing\"**:\n",
    "  playing  \n",
    "  (short sequence, but requires \"playing\" to exist in the vocabulary)\n",
    "\n",
    "- Subword tokenization of **\"playing\"**:\n",
    "  play, ing  \n",
    "\n",
    "Another example:\n",
    "\n",
    "- Word-level tokenization of **\"neurobiologist\"** might produce:\n",
    "  [UNK]  \n",
    "  if the word is not in the vocabulary.\n",
    "\n",
    "- Subword tokenization might produce:\n",
    "  neuro, bio, logist  \n",
    "\n",
    "This preserves meaningful parts of the word and avoids losing information.\n",
    "\n",
    "Subword methods (such as Byte Pair Encoding or WordPiece) work by identifying frequently occurring character combinations and merging them into tokens. Over time, common word fragments become stable units, while rare words are decomposed into smaller known pieces.\n",
    "\n",
    "This approach provides:\n",
    "\n",
    "- A manageable vocabulary size  \n",
    "- Shorter sequences than character-level tokenization  \n",
    "- Fewer unknown tokens than word-level tokenization  \n",
    "\n",
    "Modern large language models (e.g., BERT, GPT) rely on subword tokenization because it balances efficiency and expressiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78310a63",
   "metadata": {},
   "source": [
    "### Getting now to the IMDb Dataset in the language way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82c4e6",
   "metadata": {},
   "source": [
    "In many cases we don't download datasets from API but, deal with directories from different places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0d9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "zip_path = keras.utils.get_file(\n",
    "    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    fname=\"imdb\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "imdb_extract_dir = pathlib.Path(zip_path) / \"aclImdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd282f35",
   "metadata": {},
   "source": [
    "In some cases we can create own for example validation sets, when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd557b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(\"imdb_train\")\n",
    "test_dir = pathlib.Path(\"imdb_test\")\n",
    "val_dir = pathlib.Path(\"imdb_val\")\n",
    "\n",
    "# Moves the test data unaltered\n",
    "shutil.copytree(imdb_extract_dir / \"test\", test_dir)\n",
    "\n",
    "# Splits the training data into a train set and a validation set\n",
    "val_percentage = 0.2\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    src_dir = imdb_extract_dir / \"train\" / category\n",
    "    src_files = os.listdir(src_dir)\n",
    "    random.Random(1337).shuffle(src_files)\n",
    "    num_val_samples = int(len(src_files) * val_percentage)\n",
    "\n",
    "    os.makedirs(val_dir / category)\n",
    "    for file in src_files[:num_val_samples]:\n",
    "        shutil.copy(src_dir / file, val_dir / category / file)\n",
    "    os.makedirs(train_dir / category)\n",
    "    for file in src_files[num_val_samples:]:\n",
    "        shutil.copy(src_dir / file, train_dir / category / file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf2c3b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import text_dataset_from_directory\n",
    "\n",
    "batch_size = 32\n",
    "train_ds = text_dataset_from_directory(train_dir, batch_size=batch_size)\n",
    "val_ds = text_dataset_from_directory(val_dir, batch_size=batch_size)\n",
    "test_ds = text_dataset_from_directory(test_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d22ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "max_tokens = 20_000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    # Learns a word-level vocabulary\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"multi_hot\",\n",
    ")\n",
    "train_ds_no_labels = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(train_ds_no_labels)\n",
    "\n",
    "bag_of_words_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "bag_of_words_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "bag_of_words_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b0c11a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 20000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(bag_of_words_train_ds.as_numpy_iterator())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "037f7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linear_classifier(max_tokens, name):\n",
    "    inputs = keras.Input(shape=(max_tokens,))\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "    model = keras.Model(inputs, outputs, name=name)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_linear_classifier(max_tokens, \"bag_of_words_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c212cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bag_of_words_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bag_of_words_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m20,001\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> (78.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,001\u001b[0m (78.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,001</span> (78.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,001\u001b[0m (78.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "469cca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8421 - loss: 0.4581 - val_accuracy: 0.8772 - val_loss: 0.3594\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2935 - val_accuracy: 0.8882 - val_loss: 0.3058\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 0.2359 - val_accuracy: 0.8906 - val_loss: 0.2840\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.2007 - val_accuracy: 0.8946 - val_loss: 0.2725\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9534 - loss: 0.1752 - val_accuracy: 0.8936 - val_loss: 0.2663\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9604 - loss: 0.1552 - val_accuracy: 0.8944 - val_loss: 0.2632\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.1389 - val_accuracy: 0.8962 - val_loss: 0.2621\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.9718 - loss: 0.1252 - val_accuracy: 0.8944 - val_loss: 0.2624\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9756 - loss: 0.1134 - val_accuracy: 0.8960 - val_loss: 0.2637\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    restore_best_weights=True,\n",
    "    patience=2,\n",
    ")\n",
    "history = model.fit(\n",
    "    bag_of_words_train_ds,\n",
    "    validation_data=bag_of_words_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4403aa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"r--\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ffcfdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8874 - loss: 0.2803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.887440025806427"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(bag_of_words_test_ds)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eb9774",
   "metadata": {},
   "source": [
    "Let us do bigrams now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a989a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 30_000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    # Learns a word-level vocabulary\n",
    "    split=\"whitespace\",\n",
    "    output_mode=\"multi_hot\",\n",
    "    # Considers all unigrams and bigrams\n",
    "    ngrams=2,\n",
    ")\n",
    "text_vectorization.adapt(train_ds_no_labels)\n",
    "\n",
    "bigram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "bigram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "bigram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9024b0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.str_('first'),\n",
       " np.str_('most'),\n",
       " np.str_('him'),\n",
       " np.str_('dont'),\n",
       " np.str_('it was'),\n",
       " np.str_('then'),\n",
       " np.str_('one of'),\n",
       " np.str_('for the')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()[100:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "311911c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8622 - loss: 0.4004 - val_accuracy: 0.8932 - val_loss: 0.3056\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.2236 - val_accuracy: 0.9028 - val_loss: 0.2665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22074bf5950>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_linear_classifier(max_tokens, \"bigram_classifier\")\n",
    "model.fit(\n",
    "    bigram_train_ds,\n",
    "    validation_data=bigram_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c3daba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.3092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.895039975643158"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(bigram_test_ds)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36e2c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 600\n",
    "max_tokens = 30_000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    # Learns a word-level vocabulary\n",
    "    split=\"whitespace\",\n",
    "    # Outputs a integer sequence of token IDs\n",
    "    output_mode=\"int\",\n",
    "    # Pads and truncates to 600 tokens\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(train_ds_no_labels)\n",
    "\n",
    "sequence_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "sequence_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")\n",
    "sequence_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y), num_parallel_calls=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80470437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 600)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(sequence_test_ds.as_numpy_iterator())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7910c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  34,  315,  448, ...,    0,    0,    0],\n",
       "       [ 152,   10,   26, ...,    0,    0,    0],\n",
       "       [1749,  158,    5, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  80,  289,    6, ...,    0,    0,    0],\n",
       "       [   4, 7663,  951, ...,    0,    0,    0],\n",
       "       [   1,   33,  982, ...,    0,    0,    0]], shape=(32, 600))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a478b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import ops\n",
    "\n",
    "class OneHotEncoding(keras.Layer):\n",
    "    def __init__(self, depth, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.depth = depth\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Flattens the inputs\n",
    "        flat_inputs = ops.reshape(ops.cast(inputs, \"int\"), [-1])\n",
    "        # Builds an identity matrix with all possible one-hot vectors\n",
    "        one_hot_vectors = ops.eye(self.depth)\n",
    "        # Uses our input token IDs to gather the correct vector for\n",
    "        # each token\n",
    "        outputs = ops.take(one_hot_vectors, flat_inputs, axis=0)\n",
    "        # Unflattens the output\n",
    "        return ops.reshape(outputs, ops.shape(inputs) + (self.depth,))\n",
    "\n",
    "one_hot_encoding = OneHotEncoding(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a212c519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 600, 30000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(sequence_train_ds.as_numpy_iterator())\n",
    "one_hot_encoding(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7006084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 64\n",
    "inputs = keras.Input(shape=(max_length,), dtype=\"int32\")\n",
    "x = one_hot_encoding(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(hidden_dim))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"lstm_with_one_hot\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2062e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_with_one_hot\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lstm_with_one_hot\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ one_hot_encoding                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OneHotEncoding</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">15,393,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ one_hot_encoding                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m30000\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mOneHotEncoding\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m15,393,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,393,409</span> (58.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,393,409\u001b[0m (58.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,393,409</span> (58.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,393,409\u001b[0m (58.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "118af658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_train_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_val_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    913\u001b[39m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[32m    914\u001b[39m   filtered_flat_args = (\n\u001b[32m    915\u001b[39m       \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.unpack_inputs(\n\u001b[32m    916\u001b[39m           bound_args\n\u001b[32m    917\u001b[39m       )\n\u001b[32m    918\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    920\u001b[39m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[32m    925\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    sequence_train_ds,\n",
    "    validation_data=sequence_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22638420",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(sequence_test_ds)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d62f54",
   "metadata": {},
   "source": [
    "What are the hidden assumptions of representing words in these way? What are we loosing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651aaf6",
   "metadata": {},
   "source": [
    "**What Are Embeddings?**\n",
    "\n",
    "Embeddings are dense vector representations of discrete symbols (such as words or tokens).\n",
    "\n",
    "Instead of representing a word as a large sparse one-hot vector, we represent it as a smaller, continuous vector that is learned during training.\n",
    "\n",
    "**From One-Hot to Embedding**\n",
    "\n",
    "Suppose vocabulary size = 30,000.\n",
    "\n",
    "One-hot representation of a word:\n",
    "\n",
    "- 30,000 dimensions  \n",
    "- All zeros except one position  \n",
    "- No notion of similarity between words  \n",
    "\n",
    "Example:\n",
    "\n",
    "\"cat\" → [0, 0, 0, ..., 1, ..., 0]\n",
    "\n",
    "Every word is equally distant from every other word.\n",
    "\n",
    "Instead, we map each word to a dense vector:\n",
    "\n",
    "\"cat\" → [0.21, -0.73, 0.44, ..., 0.09]\n",
    "\n",
    "Typical embedding sizes:\n",
    "- 50\n",
    "- 100\n",
    "- 128\n",
    "- 300\n",
    "\n",
    "So instead of 30,000 dimensions, we may use 128.\n",
    "\n",
    "What Makes Embeddings Powerful?\n",
    "\n",
    "Embeddings are learned.\n",
    "\n",
    "During training, the model adjusts these vectors so that:\n",
    "\n",
    "- Words used in similar contexts get similar vectors  \n",
    "- Semantic relationships are captured  \n",
    "\n",
    "For example:\n",
    "\n",
    "vec(\"king\") − vec(\"man\") + vec(\"woman\") ≈ vec(\"queen\")\n",
    "\n",
    "This happens because embeddings encode patterns from data.\n",
    "\n",
    "**How They Work in a Model**\n",
    "\n",
    "An embedding layer is essentially a lookup table:\n",
    "\n",
    "Input:\n",
    "token ID (e.g., 532)\n",
    "\n",
    "Output:\n",
    "the corresponding dense vector\n",
    "\n",
    "If embedding dimension = 128 and sequence length = 600:\n",
    "\n",
    "Input shape:\n",
    "(batch_size, 600)\n",
    "\n",
    "Output shape:\n",
    "(batch_size, 600, 128)\n",
    "\n",
    "Now each token is represented by a meaningful feature vector.\n",
    "\n",
    "**Why Not Use One-Hot?**\n",
    "\n",
    "One-hot vectors:\n",
    "\n",
    "- Very large  \n",
    "- Mostly zeros  \n",
    "- No semantic similarity  \n",
    "\n",
    "Embeddings:\n",
    "\n",
    "- Compact  \n",
    "- Trainable  \n",
    "- Capture meaning  \n",
    "- Computationally efficient  \n",
    "\n",
    "One-hot encoding says:\n",
    "\n",
    "\"This word is word number 532.\"\n",
    "\n",
    "Embeddings say:\n",
    "\n",
    "\"This word has these semantic properties.\"\n",
    "\n",
    "That is why modern NLP models use embeddings instead of one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a2838",
   "metadata": {},
   "source": [
    "<img src=\"../img/embedding.png\" alt=\"Embedding space\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b3f58",
   "metadata": {},
   "source": [
    "An embedding layer is simply a matrix:\n",
    "\n",
    "$$\n",
    "E \\in \\mathbb{R}^{V \\times d}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(V\\) = vocabulary size  \n",
    "- \\(d\\) = embedding dimension  \n",
    "\n",
    "Each row of this matrix corresponds to one word.\n",
    "\n",
    "When a token ID is given, the model:\n",
    "\n",
    "- Looks up the corresponding row  \n",
    "- Returns that vector  \n",
    "\n",
    "So embeddings are a lookup into a trainable matrix.\n",
    "\n",
    "The embeddings are learned during backpropagation. \n",
    "\n",
    "- The model computes loss  \n",
    "- Gradients flow backward  \n",
    "- The embedding matrix is updated  \n",
    "- Word vectors adjust to minimize the loss  \n",
    "\n",
    "Over time:\n",
    "\n",
    "- Words appearing in similar contexts get similar vectors  \n",
    "- Semantic relationships emerge  \n",
    "\n",
    "The model is not told what \"cat\" means.\n",
    "It learns from patterns in data.\n",
    "\n",
    "Embedding is mathematically equivalent to:\n",
    "\n",
    "One-hot vector × Weight matrix\n",
    "\n",
    "If:\n",
    "\n",
    "- One-hot vector = size \\(V\\)  \n",
    "- Weight matrix = \\(V \\times d\\)\n",
    "\n",
    "Multiplying them selects one row of the matrix.\n",
    "\n",
    "That row is the embedding.\n",
    "\n",
    "So an embedding layer is just a more efficient implementation of this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ec17b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 64\n",
    "inputs = keras.Input(shape=(max_length,), dtype=\"int32\")\n",
    "x = keras.layers.Embedding(\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=hidden_dim,\n",
    "    mask_zero=True,\n",
    ")(inputs)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(hidden_dim))(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs, name=\"lstm_with_embedding\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cc70480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_with_embedding\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lstm_with_embedding\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920,000</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │  \u001b[38;5;34m1,920,000\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m66,048\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,986,177</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,986,177\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,986,177</span> (7.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,986,177\u001b[0m (7.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92c8bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m189/625\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:59\u001b[0m 825ms/step - accuracy: 0.5807 - loss: 0.6674"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_train_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_val_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m test_loss, test_acc = model.evaluate(sequence_test_ds)\n\u001b[32m      9\u001b[39m test_acc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\glono\\OneDrive\\Documents\\Dydaktyka\\Koźmiński\\dlenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    sequence_train_ds,\n",
    "    validation_data=sequence_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "test_loss, test_acc = model.evaluate(sequence_test_ds)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f402df",
   "metadata": {},
   "source": [
    "What about cases when we have so much text that the embeddings cannot be learned efficiently during training? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95715707",
   "metadata": {},
   "source": [
    "<img src=\"../img/masking.png\" alt=\"Masking tokens\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
