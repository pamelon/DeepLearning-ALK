# Grading and project

During the subject you can gather 100 points. 

Grading is based on two factors: 
1. Engagement and participation in classes - 20 points
2. Project - 80 points

100 points make 100%, grades are as follows:

```
<51; 60) % 3
<61; 70) % 3.5
<71; 80) % 4
<81; 90) % 4.5
>= 91% 5
```

## Project 

The project is done in pairs. Please choose someone with a similar ML/DL experience. This is gonna help both of you take the most from this project. For the project you need to choose one of the following datasets: 

1. [Fashion MNIST Dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist)
- If you know the basic MNIST this is a spiced up version dealing with fashion
- Dataset of Zalando's article images, gray-scale pictures, belonging to 10 classes
- Picture dimentions 28x28, in total 784 pixels
- **Goal**: Train a DL model to recognize articles of clothing (Classification)

2. [Weather Dataset](https://www.kaggle.com/arnab132/weather-dataset)
- If you worked with DL before and want something more challangening this is the dataset for you
- This dataset needs way more planning, conseptualising and data architecture and preparation.
- This is a tabular dataset consisnting of distinct measurements of weather conditions with summaries written in plain text.
- **Goal**: Train a DL model to predict temperature for the next day, based on three day window. Model gets data from last three days - outputs the predited temperature for the next day. As you can guess, uou cannot use apparent_temperature column anywhere in your predictions (Regression)

3. [Enron Email Dataset](https://www.kaggle.com/datasets/wcukierski/enron-email-dataset)
- The Enron email dataset contains approximately 500,000 emails generated by employees of the Enron Corporation. 
- It was obtained by the Federal Energy Regulatory Commission during its investigation of Enron's collapse.
- This is a dataset perfect for an NLP analysis. It needs some extra deep dives into NLP methods.
- **Goal**: Prepare the data and figure out main topics of conversations (Topic Modellling)

In the project your main objective is to learn. You can use any framework you like. 
Pure Tensorflow, Keras, PyTorch. If you are into it you can always build your own neural net from scratch (I'm not commiting to debugging it though)!

## Results

The results I am expecting at the end of your projects, regardless of the project dataset is:
- Data exploration and conclusions from that process (What you found? How that influenced your netork architecture?)
- Feature engineering and reasons for it (Why you decided to choose such features? How your results were based on features?)
- What was your network architecture?
- What framework and methods did you use? Why?
- What issues you had? What problems you found while dealing with the dataset?

This all needs to be included in the frinal presentation during the last class.
Remember that the presentations are made by each team **for your collegues**. Show what you have learned so that we all can leave this class knowing a bit more ‚ò∫Ô∏è

## AI Tools

You are allowed to use AI tools (including generative AI) during your project.

However:

If you use them, you must understand what they generate.
You must be able to explain every architectural choice, every loss function, and every line of code you present.

If something was generated with AI and you cannot explain it ‚Äî it should not be in your project.

Use AI as a tool for exploration, debugging, or acceleration.
But the reasoning, interpretation, and conclusions must be yours.

When in doubt, look to the [Ko≈ºmi≈Ñski GenAI Guidelines](https://www.kozminski.edu.pl/en/news/kozminski-university-recommendations-regarding-use-ai-based-generators-such-chatgpt) or ask (this time) me! not only generative AI tools ü•∞

Please include in your code, presentation or report if you've used generative tools, and for what. 
This is an opportunity for all of us to learn new ways to use cool tools.